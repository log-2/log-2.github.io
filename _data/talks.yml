- type: Future Talks
  members:
    - speaker: Francesco Di Giovanni (University of Cambridge)
    date: March 30, 2023
    title: "On over-squashing in Graph Neural Networks: from theoretical understanding to graph-rewiring solutions"
    abstract: "In this talk I will provide an overview on the over-squashing phenomenon for Message Passing Neural Networks (MPNN) and on different strategies that have been proposed to tackle this problem that fall under the class of graph-rewiring techniques. I will start by discussing existing works in the literature that have shaped the problem. I will then go through a recent paper where we provide a more rigorous theoretical understanding of over-squashing, connecting it to classical random-walk properties of the graph. This allows us to draw a unified framework to justify why different rewiring operations studied thus far, do indeed help mitigate over-squashing. I will then discuss a new work where we introduce notions of dynamic edge addition and delay mechanism, resulting in a novel way of treating the underlying graph which can enhance any existing MPNN and achieve strong performances on long-range tasks. Finally, I will try to focus on the bigger picture and on why I think these directions of research are important to understand if Graph Neural Networks are here to stay or not."
    bio: "https://francescodgv.github.io/"
      
- type: Past Talks
  members:
    - speaker: Francesco Di Giovanni (University of Cambridge)
        date: March 30, 2023
        title: "On over-squashing in Graph Neural Networks: from theoretical understanding to graph-rewiring solutions"
        abstract: "In this talk I will provide an overview on the over-squashing phenomenon for Message Passing Neural Networks (MPNN) and on different strategies that have been proposed to tackle this problem that fall under the class of graph-rewiring techniques. I will start by discussing existing works in the literature that have shaped the problem. I will then go through a recent paper where we provide a more rigorous theoretical understanding of over-squashing, connecting it to classical random-walk properties of the graph. This allows us to draw a unified framework to justify why different rewiring operations studied thus far, do indeed help mitigate over-squashing. I will then discuss a new work where we introduce notions of dynamic edge addition and delay mechanism, resulting in a novel way of treating the underlying graph which can enhance any existing MPNN and achieve strong performances on long-range tasks. Finally, I will try to focus on the bigger picture and on why I think these directions of research are important to understand if Graph Neural Networks are here to stay or not."
        bio: "https://francescodgv.github.io/"
    - speaker: Petar Veličković (DeepMind)
      date: March 7, 2023
      title: "Neural Algorithmic Reasoning"
      abstract: "Neural networks that are able to reliably execute algorithmic computation may hold transformative potential to both machine learning and theoretical computer science. On one hand, they could enable the kind of extrapolative generalisation scarcely seen with deep learning models. On another, they may allow for running classical algorithms on inputs previously considered inaccessible to them. Both of these promises are shepherded by the neural algorithmic reasoning blueprint, which has been recently proposed in a position paper I co-authored with Charles Blundell. On paper, this is a remarkably elegant pipeline for reasoning on natural inputs which carefully leverages the tried-and-tested power of deep neural networks as feature extractors. In practice, how far did we actually take it? In this tutorial, we aim to provide the foundations needed to answer three key questions of neural algorithmic reasoning: how to develop neural networks that execute algorithmic computation, how to deploy such neural networks in real-world problems, and how to deepen their theoretical links to classical algorithms."
      bio: "https://petar-v.com/"
    - speaker: Fabrizio Frasca (Imperial College London)
      date: March 6, 2023
      title: "Pack your subgraphs - A journey into subgraphs for powerful Graph Neural Networks"
      abstract: "Whilst considered the leading architectures for Deep Learning on graph-structured data, Message Passing Neural Networks (MPNNs) are intrinsically bounded in their expressive power by the WL heuristic for graph isomorphism testing - a limitation that has recently ignited prolific research aiming at breaking this fundamental bottleneck. Yet, the most prominent approaches either suffer from high computational complexity and weak inductive biases or require some form of domain knowledge for their effective application. In this talk - which I structure in two parts - I will argue that these aforementioned limitations can be mitigated by resorting to a principled modelling of subgraphs. We will first observe that graphs not distinguishable by MPNNs often contain distinguishable subgraphs. In the first part of the talk, we will build upon this intuition to design a novel framework dubbed Equivariant Subgraph Aggregation Networks (ESAN), prescribing to represent a graph as a bag of subgraphs returned by a pre-specified policy and to process it with a suitable equivariant architecture. We show that this approach effectively increases the expressive power of both MPNNs and more expressive architectures, and study the impact of its design choices. Interestingly, we notice a surge in concurrent approaches which - sometimes unwittingly - make use of subgraphs for powerful graph representations. In the second part of the talk we will focus on the most prominent form of these methods: those where subgraphs are directly “generated” by nodes in the original graph (node-based methods). A novel symmetry analysis allows to unify and better characterise this class of approaches: we prove an upper-bound on their expressive power and conceive a framework serving as a design space for equivariant node-based subgraph architectures. Finally, we introduce a novel instantiation of this framework: a new method dubbed SUN, which captures previous architectures while providing better empirical performance on multiple benchmarks."
      bio: "https://noired.github.io/"   


#- type: Past Talks
#  members:
#   - speaker: Petar Veličković (DeepMind)
#      date: March 7, 2023
#      title: "Neural Algorithmic Reasoning"
#      abstract: "Neural networks that are able to reliably execute algorithmic computation may hold transformative potential to both machine learning and theoretical computer science. On one hand, they could enable the kind of extrapolative generalisation scarcely seen with deep learning models. On another, they may allow for running classical algorithms on inputs previously considered inaccessible to them. Both of these promises are shepherded by the neural algorithmic reasoning blueprint, which has been recently proposed in a position paper I co-authored with Charles Blundell. On paper, this is a remarkably elegant pipeline for reasoning on natural inputs which carefully leverages the tried-and-tested power of deep neural networks as feature extractors. In practice, how far did we actually take it? In this tutorial, we aim to provide the foundations needed to answer three key questions of neural algorithmic reasoning: how to develop neural networks that execute algorithmic computation, how to deploy such neural networks in real-world problems, and how to deepen their theoretical links to classical algorithms."
#      bio: "https://petar-v.com/"
#      link: "https://arxiv.org/abs/2105.02761"
#    - speaker: Fabrizio Frasca (Imperial College London)
#      date: March 6, 2023
#      title: "Pack your subgraphs - A journey into subgraphs for powerful Graph Neural Networks"
#      abstract: "Whilst considered the leading architectures for Deep Learning on graph-structured data, Message Passing Neural Networks (MPNNs) are intrinsically bounded in their expressive power by the WL heuristic for graph isomorphism testing - a limitation that has recently ignited prolific research aiming at breaking this fundamental bottleneck. Yet, the most prominent approaches either suffer from high computational complexity and weak inductive biases or require some form of domain knowledge for their effective application. In this talk - which I structure in two parts - I will argue that these aforementioned limitations can be mitigated by resorting to a principled modelling of subgraphs. We will first observe that graphs not distinguishable by MPNNs often contain distinguishable subgraphs. In the first part of the talk, we will build upon this intuition to design a novel framework dubbed Equivariant Subgraph Aggregation Networks (ESAN), prescribing to represent a graph as a bag of subgraphs returned by a pre-specified policy and to process it with a suitable equivariant architecture. We show that this approach effectively increases the expressive power of both MPNNs and more expressive architectures, and study the impact of its design choices. Interestingly, we notice a surge in concurrent approaches which - sometimes unwittingly - make use of subgraphs for powerful graph representations. In the second part of the talk we will focus on the most prominent form of these methods: those where subgraphs are directly “generated” by nodes in the original graph (node-based methods). A novel symmetry analysis allows to unify and better characterise this class of approaches: we prove an upper-bound on their expressive power and conceive a framework serving as a design space for equivariant node-based subgraph architectures. Finally, we introduce a novel instantiation of this framework: a new method dubbed SUN, which captures previous architectures while providing better empirical performance on multiple benchmarks."
#      bio: "https://noired.github.io/"
#      link: https://arxiv.org/abs/2110.02910
#      link2: https://arxiv.org/abs/2206.11140

    

 
